{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 작은 도움이라도 될 수 있길 바라며 내가 아는만큼 최대한 자세하게 적으려고 노력했어... \n",
    "#### 설명은 코드아래에 명시해 놓았으니 참고해!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 관련된 라이브러리 import\n",
    "  - tensorflow랑 numpy는 알 것 같아서 따로 안적음.\n",
    "  - tqdm은 learning 시에 progress bar를 표현해줌.(원작자가 해놓아서 수정하지 않음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dataset은 mnist를 활용하였음. mnist data set의 input_data를 import하는 구문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-6fa84048fdd1>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\volquelme\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\volquelme\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\volquelme\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\volquelme\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\volquelme\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import된 input_data를 mnist 변수에 할당하고 주어진 경로 \"./mnist/data/\"에 저장함\n",
    "  - one_hot = True 옵션은 label(0~9의 10개)를 0과 1로 치환해주는 코드임.(ex : 2 -> 0010000000, 7 -> 0000000100)\n",
    "  - WARNING은 새로운 버전의 mnist data set이 있다는 안내이니 무시해도 무방"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images, training_labels, test_images, test_labels = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels\n",
    "training_images = training_images.reshape(-1, 28, 28, 1)\n",
    "test_images = test_images.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mnist data set을 training/test image와 label로 나누어 변수에 할당함.\n",
    "#### training/test_images는 28 X 28 size의 picture 이나, 변수 할당 시 [-1, 786(28 X 28)]로 변환됨. 따라서 image로 활용하기 위해(ResNet이 이미지를 분할하는 concept 이므로) reshape함.( -1 : n개의 자료, 28, 28 : size, 1 : color(black/white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### input되는 자료를 할당하기 위한 placeholder 지정\n",
    "  - x : image, y : label이 들어가므로 위의 수치가 이해될 것임, None은 n개라는 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNET(input) :\n",
    "    L = tf.nn.conv2d(input, tf.Variable(tf.random_normal([3, 3, 32, 32])), strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "    L = tf.nn.relu(L)\n",
    "    L = tf.nn.conv2d(L, tf.Variable(tf.random_normal([3, 3, 32, 32])), strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "    L = input + L\n",
    "    L = tf.nn.relu(L)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResNet concept 구현을 위한 함수 선언\n",
    "  - conv2d는 convolutional layer 구현을 위한 tool로 3 X 3 size인 32개의 filter를 활용, stride는 건너뛰는 값(1X1), padding이 same일 경우 stride가 1x1일 때, input과 output의 사이즈가 동일함(?, 28, 28, 32)\n",
    "  - 이후, relu 통과\n",
    "  - conv2d 재시행\n",
    "  - 기존 input 값을 출력된 값이 더함(ResNET 핵심으로 gradient vanishing 방지, 깊은 layer를 쌓을 수 있으나, 여기서는 2단만 구현)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cnn 관련 이론은 다음의 동영상을 보면 이해될 것임. https://www.youtube.com/watch?v=Em63mknbtWo&list=PLlMkM4tgfjnLSOjrEJN31gZATbcj_MpUm&index=35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = tf.nn.conv2d(x, tf.Variable(tf.random_normal([3, 3, 1, 32])), strides = [1,1,1,1], padding = 'SAME')\n",
    "for i in range(5) :\n",
    "    L = ResNET(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResNet에 넣기위해 초기 Layer(L)을 3x3 fliter 32개를 활용하여 분할(하지만 padding 때문에 size는 같음)\n",
    "#### ResNet에서 5번 반복됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D_12:0\", shape=(?, 28, 28, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "last = tf.nn.conv2d(L, tf.Variable(tf.random_normal([3, 3, 32, 1])), strides = [1,1,1,1], padding = 'SAME')\n",
    "print(last) # last shape chk'\n",
    "flatten = tf.reshape(last, [-1, last.get_shape()[1:4].num_elements()])\n",
    "W = tf.Variable(tf.random_normal([last.get_shape()[1:4].num_elements(), 10]))\n",
    "result = tf.matmul(flatten, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### last : fully conected layer에 연결하기 위해 마지막 flitering 후 출력layer를 1장으로 변경\n",
    "#### flatten = last를 다시 [-1, n] 형태로 변환( n : 28 * 28 * 1)\n",
    "#### W : softmax 활용을 위해 임의의 W값 지정 및 변수선언, output이 10종류 이므로 10\n",
    "#### result : W * X로 이해하면 됨.(logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = result, labels = y))\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(result, 1), tf.argmax(y, 1)), dtype = tf.float32))\n",
    "optimizer = tf.train.AdamOptimizer(0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cost : softmax함수의 cost 함수인 cross entropy 사용\n",
    "#### accuracy 계산은 예측값과 label 최대값의 index가 같은지(one_hot 이므로) 확인하고 true이면 1로 casting하여 평균을 구함.\n",
    "  - 2번해서 1번 맞으면 (1 + 0) / 2로 구하는 식임.\n",
    "#### optimizer는 Adam 사용(optimizer 고르는 건 솔직히 잘 모르겠음.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### variable initializing, run session\n",
    "#### 보기 불편해서 아래코드 설명은 여기다 적음\n",
    "  - batch_size : 한번에 50개의 자료(그림)을 가져옴([j*batch_size:(j+1)*batch_size,:,:,:]중 뒤에 :, :, :은 잘 모르겠음ㅠㅠㅠ)\n",
    "  - 첫번째 for roop는 epoch으로 10으로 임의지정(오래걸려서... 원작은 100)\n",
    "  - 두번째 for roop는 실제 batch 및 training이 이루어짐.\n",
    "  - cost는 epoch마다 list에 넣어서 평균으로 구함.\n",
    "  - accuracy는 test dataset을 활용하여 구함.(training dataset 미활용)\n",
    "  - accuracy가 떨어지는데... 원작자대로 하면 85%정도 나오는데... CPU로 돌리면 한시간 걸릴 것 같음. GPU 시도해봤는데 잘 안됨 ㅠㅠ\n",
    "  - 참고한 블로그 주소 https://blog.naver.com/et2035/221371125386"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce90ba433d774def81e13ee7e9967c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 -th Epoch\n",
      "Cost : 4457044600000.0\n",
      "1 -th Epoch\n",
      "Accuracy :  0.1507\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a05de79a34c64c888d1fad616a94b2b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2 -th Epoch\n",
      "Cost : 2760486700000.0\n",
      "2 -th Epoch\n",
      "Accuracy :  0.1786\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "606475abe1634799a9075042e7325494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 -th Epoch\n",
      "Cost : 2040985400000.0\n",
      "3 -th Epoch\n",
      "Accuracy :  0.1939\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d002098bfe427bba030eeeee58d6d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4 -th Epoch\n",
      "Cost : 1615404700000.0\n",
      "4 -th Epoch\n",
      "Accuracy :  0.2021\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a2847afa1eb4288a0ebf54063952039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 -th Epoch\n",
      "Cost : 1331382200000.0\n",
      "5 -th Epoch\n",
      "Accuracy :  0.2158\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "499f0b8451194b508ef910c32e03d41e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6 -th Epoch\n",
      "Cost : 1127222000000.0\n",
      "6 -th Epoch\n",
      "Accuracy :  0.2387\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19737b2c31de4543879d5e3d813efa3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7 -th Epoch\n",
      "Cost : 974739000000.0\n",
      "7 -th Epoch\n",
      "Accuracy :  0.2536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8161eb4f31b4a0b9bb732cb7ec93794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "8 -th Epoch\n",
      "Cost : 856860600000.0\n",
      "8 -th Epoch\n",
      "Accuracy :  0.2533\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5510c45c2522406b9a336abaecc57602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "9 -th Epoch\n",
      "Cost : 763760740000.0\n",
      "9 -th Epoch\n",
      "Accuracy :  0.2605\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e612288a12422598aa077b6b1d83c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 -th Epoch\n",
      "Cost : 688169750000.0\n",
      "10 -th Epoch\n",
      "Accuracy :  0.2698\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "cost_list = []\n",
    "acc_list =[]\n",
    "for i in range(10) :\n",
    "    for j in tqdm.tqdm_notebook(range(5)) :\n",
    "        _, c = sess.run([optimizer, cost], feed_dict = {x:training_images[j*batch_size:(j+1)*batch_size,:,:,:], y:training_labels[j*batch_size:(j+1)*batch_size,:]})\n",
    "        cost_list.append(c)\n",
    "    print(i+1, '-th Epoch\\nCost :', np.mean(cost_list))\n",
    "    print(i+1, '-th Epoch\\nAccuracy : ', sess.run(accuracy, feed_dict={x:test_images, y:test_labels}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
